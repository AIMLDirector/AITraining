{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d89e50-df7b-451a-ab4e-e7813fc1d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f568481-995a-47f6-a165-856afca6a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723adf4b-01d2-4fcd-8164-9007d7360f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'of', 'the', 'applications', 'you', 'build', 'with', 'LangChain', 'will', 'contain', 'multiple', 'steps', 'with', 'multiple', 'invocations', 'of', 'LLM', 'calls', '.', 'As', 'these', 'applications', 'get', 'more', 'and', 'more', 'complex', ',', 'it', 'becomes', 'crucial', 'to', 'be', 'able', 'to', 'inspect', 'what', 'exactly', 'is', 'going', 'on', 'inside', 'your', 'chain', 'or', 'agent', '.']\n"
     ]
    }
   ],
   "source": [
    "word_token_sentence = word_tokenize(sentence1)\n",
    "print (word_token_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2648190-781a-4f1a-bbe9-f6f3555ec691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'applications', 'build', 'LangChain', 'contain', 'multiple', 'steps', 'multiple', 'invocations', 'LLM', 'calls', '.', 'applications', 'get', 'complex', ',', 'becomes', 'crucial', 'able', 'inspect', 'exactly', 'going', 'inside', 'chain', 'agent', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "word_stop_sentence = [w for w in word_token_sentence if w.casefold() not in stop_words]\n",
    "print(word_stop_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8089415c-a053-4930-9c69-da4f6bd17e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Many', 'applications', 'build', 'LangChain', 'contain', 'multiple', 'steps', 'multiple', 'invocations', 'LLM', 'calls', 'applications', 'get', 'complex', 'becomes', 'crucial', 'able', 'inspect', 'exactly', 'going', 'inside', 'chain', 'agent']\n"
     ]
    }
   ],
   "source": [
    "stopwordcust = {\",\", \".\"}\n",
    "word_stop_sentence1 = [w for w in word_stop_sentence if w.casefold() not in stopwordcust]\n",
    "print(word_stop_sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e312c5-371c-4f98-90ac-3640abe83e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pstemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f319b88d-52fa-40c5-864c-f910da331549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mani\n",
      "applic\n",
      "build\n",
      "langchain\n",
      "contain\n",
      "multipl\n",
      "step\n",
      "multipl\n",
      "invoc\n",
      "llm\n",
      "call\n",
      "applic\n",
      "get\n",
      "complex\n",
      "becom\n",
      "crucial\n",
      "abl\n",
      "inspect\n",
      "exactli\n",
      "go\n",
      "insid\n",
      "chain\n",
      "agent\n"
     ]
    }
   ],
   "source": [
    "word_stem_sentence1 = [Pstemmer.stem(word) for word in word_stop_sentence1]\n",
    "for i in word_stem_sentence1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca57fe1f-a263-4a7a-818f-f568cf16f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lstemmer = LancasterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc36673-745b-44b4-9f11-0589aadfe6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many\n",
      "apply\n",
      "build\n",
      "langchain\n",
      "contain\n",
      "multipl\n",
      "step\n",
      "multipl\n",
      "invoc\n",
      "llm\n",
      "cal\n",
      "apply\n",
      "get\n",
      "complex\n",
      "becom\n",
      "cruc\n",
      "abl\n",
      "inspect\n",
      "exact\n",
      "going\n",
      "insid\n",
      "chain\n",
      "ag\n"
     ]
    }
   ],
   "source": [
    "word_stem_sentence1 = [Lstemmer.stem(word) for word in word_stop_sentence1]\n",
    "for i in word_stem_sentence1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68fead88-3d3c-4380-9d9d-5780a5f9d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mani\n",
      "applic\n",
      "build\n",
      "langchain\n",
      "contain\n",
      "multipl\n",
      "step\n",
      "multipl\n",
      "invoc\n",
      "llm\n",
      "call\n",
      "applic\n",
      "get\n",
      "complex\n",
      "becom\n",
      "crucial\n",
      "abl\n",
      "inspect\n",
      "exact\n",
      "go\n",
      "insid\n",
      "chain\n",
      "agent\n"
     ]
    }
   ],
   "source": [
    "Sstemmer = SnowballStemmer(\"english\")\n",
    "word_stem_sentence1 = [Sstemmer.stem(word) for word in word_stop_sentence1]\n",
    "for i in word_stem_sentence1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55b14118-216c-468d-94cc-77ab4842af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7741b895-19e3-4c04-8961-d194fb25bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many\n",
      "application\n",
      "build\n",
      "LangChain\n",
      "contain\n",
      "multiple\n",
      "step\n",
      "multiple\n",
      "invocation\n",
      "LLM\n",
      "call\n",
      "application\n",
      "get\n",
      "complex\n",
      "becomes\n",
      "crucial\n",
      "able\n",
      "inspect\n",
      "exactly\n",
      "going\n",
      "inside\n",
      "chain\n",
      "agent\n"
     ]
    }
   ],
   "source": [
    "Lemmatized_word = WordNetLemmatizer()\n",
    "word_lem_sentence1 = [Lemmatized_word.lemmatize(word) for word in word_stop_sentence1]\n",
    "for i in word_lem_sentence1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c2ba856-80ed-43a6-ac1b-aa4d34834a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Many', 'JJ')\n",
      "('application', 'NN')\n",
      "('build', 'VBP')\n",
      "('LangChain', 'NNP')\n",
      "('contain', 'NN')\n",
      "('multiple', 'JJ')\n",
      "('step', 'NN')\n",
      "('multiple', 'JJ')\n",
      "('invocation', 'NN')\n",
      "('LLM', 'NNP')\n",
      "('call', 'NN')\n",
      "('application', 'NN')\n",
      "('get', 'NN')\n",
      "('complex', 'JJ')\n",
      "('becomes', 'VBZ')\n",
      "('crucial', 'JJ')\n",
      "('able', 'JJ')\n",
      "('inspect', 'NN')\n",
      "('exactly', 'RB')\n",
      "('going', 'VBG')\n",
      "('inside', 'RB')\n",
      "('chain', 'NN')\n",
      "('agent', 'NN')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "word_POS_sentence1 = nltk.pos_tag(word_lem_sentence1)\n",
    "for i in word_POS_sentence1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e794b97c-9014-4421-a58b-922961b730fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Many', 'JJ')\n",
      "('application', 'NN')\n",
      "('build', 'VBP')\n",
      "(ORGANIZATION LangChain/NNP)\n",
      "('contain', 'NN')\n",
      "('multiple', 'JJ')\n",
      "('step', 'NN')\n",
      "('multiple', 'JJ')\n",
      "('invocation', 'NN')\n",
      "(ORGANIZATION LLM/NNP)\n",
      "('call', 'NN')\n",
      "('application', 'NN')\n",
      "('get', 'NN')\n",
      "('complex', 'JJ')\n",
      "('becomes', 'VBZ')\n",
      "('crucial', 'JJ')\n",
      "('able', 'JJ')\n",
      "('inspect', 'NN')\n",
      "('exactly', 'RB')\n",
      "('going', 'VBG')\n",
      "('inside', 'RB')\n",
      "('chain', 'NN')\n",
      "('agent', 'NN')\n"
     ]
    }
   ],
   "source": [
    "from nltk  import ne_chunk\n",
    "word_NER_sentence1 = ne_chunk(word_POS_sentence1)\n",
    "for i in word_NER_sentence1:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed45d545-68c4-46e2-9ff0-6c145dd75e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('london', 'NN')\n",
      "(PERSON Gandhi/NNP)\n",
      "('microsoft', 'NN')\n"
     ]
    }
   ],
   "source": [
    "wordlist = [\"london\", \"Gandhi\", \"microsoft\"]\n",
    "wordlist_pos_tag = nltk.pos_tag(wordlist)\n",
    "#print(wordlist_pos_tag)\n",
    "\n",
    "wordlist_NER_tag = nltk.ne_chunk(wordlist_pos_tag)\n",
    "\n",
    "for i in wordlist_NER_tag:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58af676c-df34-4605-b2dd-7703a0576819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentinment analysis in social media\n",
    "# language learning  and translation\n",
    "# chatbot \n",
    "# information extraction\n",
    "# text generation and summarizations\n",
    "\n",
    "# nltk ,spacy,textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a9448-e769-44ec-b97e-4952393aac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [w for w in word_stop_sentence if w.casefold() not in stopwordcust] - one line python coding \n",
    "\n",
    "word2 = []\n",
    "for w in word_stop_sentence:  \n",
    "    if w.casefold() not in stopwordcust:\n",
    "        word2.append(w)\n",
    "        print(word2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIvenv",
   "language": "python",
   "name": "aivenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
